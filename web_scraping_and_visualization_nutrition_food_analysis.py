# -*- coding: utf-8 -*-
"""Web Scraping and Visualization: Nutrition Food Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GQBpKTpD4JCEckX1E5gd5O4FNLFlE1VI

###ส่วนที่ 1 ดึงข้อมูลเว็บ ที่เก็บข้อมูลแคลเลอลี่ของ อาหาร ขนม เครื่องดื่มต่างๆ
"""

import pandas as pd
from bs4 import BeautifulSoup
import requests

url = "http://event.sanook.com/health/calories/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
tables = soup.find_all('table')

data = []
table1 = tables[0]
rows = table1.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    name = cols[0].get_text(strip=True)
    quantity = cols[1].get_text(strip=True)
    calories = cols[2].get_text(strip=True)
    data.append({ "ชื่อ": name, "จํานวน": quantity, "ปริมาณแคลเลอรี่": calories,"Category": "เครื่องดื่ม"})

table2 = tables[1]
rows = table2.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    name = cols[0].get_text(strip=True)
    quantity = cols[1].get_text(strip=True)
    calories = cols[2].get_text(strip=True)
    data.append({ "ชื่อ": name, "จํานวน": quantity, "ปริมาณแคลเลอรี่": calories,"Category": "ผลไม้ ของกินเล่น"})

table3 = tables[2]
rows = table3.find_all('tr')

for row in rows[1:]:
    cols = row.find_all('td')
    name = cols[0].get_text(strip=True)
    quantity = cols[1].get_text(strip=True)
    calories = cols[2].get_text(strip=True)
    data.append({ "ชื่อ": name, "จํานวน": quantity, "ปริมาณแคลเลอรี่": calories,"Category": "อาหาร"})

df = pd.DataFrame(data)
df['ปริมาณแคลเลอรี่'] = df['ปริมาณแคลเลอรี่'].str.replace(r'[^0-9]', '', regex=True)
df

df.to_csv('/content/drive/MyDrive/2567Colab statCamp/calories_food.csv', index=False)

"""ส่วนที่2 ดึงข้อมูลวัตถุดิบ เพื่อเช็ค แคลเลอลี่ โปรตีน คาร์โบไฮเดต ไขมัน"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_carbohydrates_page(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")

    table = soup.find("table")
    rows = table.find_all("tr")
    data = []
    for row in rows[1:]:  # ข้ามแถวหัวตารางไป
        cols = row.find_all("td")  # หาคอลัมน์ในแถว
        if len(cols) == 5:  # ถ้าจำนวนคอลัมน์ในแถวคือ 5 (ข้อมูลครบ)
            food_type = cols[0].get_text(strip=True)  # ดึงชื่อประเภทอาหาร
            energy = cols[1].get_text(strip=True)  # ดึงค่าพลังงาน
            protein = cols[2].get_text(strip=True)  # ดึงปริมาณโปรตีน
            fat = cols[3].get_text(strip=True)  # ดึงปริมาณไขมัน
            carbohydrates = cols[4].get_text(strip=True)  # ดึงปริมาณคาร์โบไฮเดรต
            data.append([food_type, energy, protein, fat, carbohydrates, "คาร์โบไฮเดรตหลัก"])  # เก็บข้อมูลและเพิ่มประเภทอาหารเป็น "คาร์โบไฮเดรตหลัก"

    df_carbohydrates = pd.DataFrame(data, columns=["วัตถุดิบอาหาร(100กรัม)", "พลังงาน", "โปรตีน", "ไขมัน", "คาร์โบไฮเดต", "ประเภทวัตถุดิบ"])
    return df_carbohydrates

# ฟังก์ชันสำหรับการดึงข้อมูลจากหน้าโปรตีน
def scrape_protein_page(url):
    response = requests.get(url)  # ส่งคำขอไปที่ URL
    soup = BeautifulSoup(response.content, "html.parser")  # แปลงเนื้อหาของเว็บให้เป็นรูปแบบที่เข้าใจได้

    # หาแท็กที่เป็นตารางที่มีข้อมูล
    table = soup.find("table")
    rows = table.find_all("tr")  # หาแถวทั้งหมดในตาราง

    # ดึงข้อมูลที่ต้องการ เช่น ประเภทอาหาร, พลังงาน, โปรตีน, ไขมัน, คาร์โบไฮเดรต
    data = []
    for row in rows[1:]:  # ข้ามแถวหัวตารางไป
        cols = row.find_all("td")  # หาคอลัมน์ในแถว
        if len(cols) == 5:  # ถ้าจำนวนคอลัมน์ในแถวคือ 5 (ข้อมูลครบ)
            food_type = cols[0].get_text(strip=True)  # ดึงชื่อประเภทอาหาร
            energy = cols[1].get_text(strip=True)  # ดึงค่าพลังงาน
            protein = cols[2].get_text(strip=True)  # ดึงปริมาณโปรตีน
            fat = cols[3].get_text(strip=True)  # ดึงปริมาณไขมัน
            carbohydrates = cols[4].get_text(strip=True)  # ดึงปริมาณคาร์โบไฮเดรต
            data.append([food_type, energy, protein, fat, carbohydrates, "โปรตีนหลัก"])  # เก็บข้อมูลและเพิ่มประเภทอาหารเป็น "โปรตีนหลัก"

    # เปลี่ยนข้อมูลที่ดึงมาเป็น DataFrame (ตารางข้อมูลใน pandas)
    df_protein = pd.DataFrame(data, columns=["วัตถุดิบอาหาร(100กรัม)", "พลังงาน", "โปรตีน", "ไขมัน", "คาร์โบไฮเดต", "ประเภทวัตถุดิบ"])
    return df_protein

# ฟังก์ชันสำหรับการดึงข้อมูลจากหน้าไขมัน
def scrape_fat_page(url):
    response = requests.get(url)  # ส่งคำขอไปที่ URL
    soup = BeautifulSoup(response.content, "html.parser")  # แปลงเนื้อหาของเว็บให้เป็นรูปแบบที่เข้าใจได้

    # หาแท็กที่เป็นตารางที่มีข้อมูล
    table = soup.find("table")
    rows = table.find_all("tr")  # หาแถวทั้งหมดในตาราง
    data = []
    for row in rows[1:]:  # ข้ามแถวหัวตารางไป
        cols = row.find_all("td")
        if len(cols) == 5:
            food_type = cols[0].get_text(strip=True)
            energy = cols[1].get_text(strip=True)
            protein = cols[2].get_text(strip=True)
            fat = cols[3].get_text(strip=True)
            carbohydrates = cols[4].get_text(strip=True)  #
            data.append([food_type, energy, protein, fat, carbohydrates, "ไขมันหลัก"])

    # เปลี่ยนข้อมูลที่ดึงมาเป็น DataFrame (ตารางข้อมูลใน pandas)
    df_fat = pd.DataFrame(data, columns=["วัตถุดิบอาหาร(100กรัม)", "พลังงาน", "โปรตีน", "ไขมัน", "คาร์โบไฮเดต", "ประเภทวัตถุดิบ"])
    return df_fat

# URLs ของหน้าเว็บ
url_carbohydrates = "https://www.thaisook.org/2023/09/14/carbohydrate/"
url_protein = "https://www.thaisook.org/2023/09/12/protein-2/"
url_fat = "https://www.thaisook.org/2023/09/19/fat/"

df_carbohydrates = scrape_carbohydrates_page(url_carbohydrates)
df_protein = scrape_protein_page(url_protein)
df_fat = scrape_fat_page(url_fat)
df_combined = pd.concat([df_carbohydrates, df_protein, df_fat], ignore_index=True)
df_combined

df_combined.to_csv('/content/drive/MyDrive/2567Colab statCamp/สาอาหารวัตถุดิบ1.csv', index=False)